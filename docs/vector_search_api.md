# ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

Minervaã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ï¼ˆã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ï¼‰æ©Ÿèƒ½ã®å®Œå…¨ãªAPIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã™ã€‚ã“ã®æ©Ÿèƒ½ã§ã¯ã€AIåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ã¯è¦‹ã¤ã‘ã‚‰ã‚Œãªã„æ„å‘³çš„ã«é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç™ºè¦‹ã§ãã¾ã™ã€‚

## ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨è¨­å®š](#ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨è¨­å®š)
3. [æ¤œç´¢æ©Ÿèƒ½](#æ¤œç´¢æ©Ÿèƒ½)
4. [ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†](#ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†)
5. [ãƒãƒƒãƒå‡¦ç†](#ãƒãƒƒãƒå‡¦ç†)
6. [ãƒ‡ãƒãƒƒã‚°ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹](#ãƒ‡ãƒãƒƒã‚°ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹)
7. [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)
8. [ä½¿ç”¨ä¾‹ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#ä½¿ç”¨ä¾‹ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼)

## æ¦‚è¦

ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã¯ä»¥ä¸‹ã®æŠ€è¡“ã‚’ä½¿ç”¨ã—ã¦å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ï¼š

- **åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«**: `all-MiniLM-L6-v2` (384æ¬¡å…ƒ)
- **ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹**: DuckDB with VSS (Vector Similarity Search)
- **é¡ä¼¼åº¦è¨ˆç®—**: ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
- **ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ–¹å¼**: HNSW (Hierarchical Navigable Small World)

### åˆ©ç”¨å¯èƒ½ãªMCPãƒ„ãƒ¼ãƒ«

| ãƒ„ãƒ¼ãƒ«å | ã‚«ãƒ†ã‚´ãƒª | ç›®çš„ |
|---------|----------|------|
| `semantic_search` | æ¤œç´¢ | è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã§ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ |
| `find_similar_notes` | æ¤œç´¢ | æŒ‡å®šãƒãƒ¼ãƒˆã«é¡ä¼¼ã™ã‚‹ãƒãƒ¼ãƒˆã‚’æ¤œç´¢ |
| `find_duplicate_notes` | æ¤œç´¢ | ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦ã«ã‚ˆã‚‹é‡è¤‡ãƒãƒ¼ãƒˆæ¤œå‡º |
| `build_vector_index` | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ |
| `build_vector_index_batch` | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | å°è¦æ¨¡ãƒãƒƒãƒã§ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ |
| `get_vector_index_status` | çŠ¶æ…‹ç¢ºèª | ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ³ã®ç¢ºèª |
| `process_batch_index` | ãƒãƒƒãƒå‡¦ç† | ä¿ç•™ä¸­ã®ãƒãƒƒãƒã‚¿ã‚¹ã‚¯å‡¦ç† |
| `get_batch_index_status` | ãƒãƒƒãƒå‡¦ç† | ãƒãƒƒãƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ç¢ºèª |
| `debug_vector_schema` | ãƒ‡ãƒãƒƒã‚° | ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è©³ç´°è¨ºæ–­ |
| `reset_vector_database` | ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ | ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å®Œå…¨ãƒªã‚»ãƒƒãƒˆ |

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨è¨­å®š

### å¿…è¦ãªä¾å­˜é–¢ä¿‚

```bash
# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install "minerva[vector]"

# ã¾ãŸã¯å€‹åˆ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install duckdb sentence-transformers numpy
```

### ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```bash
# åŸºæœ¬è¨­å®šï¼ˆå¿…é ˆï¼‰
VECTOR_SEARCH_ENABLED=true

# è©³ç´°è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
VECTOR_DB_PATH=/custom/path/vectors.db  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {vault}/.minerva/vectors.db
EMBEDDING_MODEL=all-MiniLM-L6-v2        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: all-MiniLM-L6-v2

# è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
AUTO_INDEX_ENABLED=true                 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: true
AUTO_INDEX_STRATEGY=batch               # immediate/batch/backgroundï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: immediateï¼‰

# ãƒãƒƒãƒå‡¦ç†è¨­å®šï¼ˆå°†æ¥å®Ÿè£…äºˆå®šï¼‰
BATCH_SIZE=10                           # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
BATCH_TIMEOUT=30.0                      # ãƒãƒƒãƒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30.0ï¼‰
```

#### è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³è©³ç´°

| è¨­å®šé …ç›® | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ | èª¬æ˜ | å®Ÿè£…çŠ¶æ³ |
|---------|-------------|------|----------|
| `VECTOR_SEARCH_ENABLED` | `false` | ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹ | âœ… å®Ÿè£…æ¸ˆã¿ |
| `VECTOR_DB_PATH` | `{vault}/.minerva/vectors.db` | ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ | âœ… å®Ÿè£…æ¸ˆã¿ |
| `EMBEDDING_MODEL` | `all-MiniLM-L6-v2` | ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å | âœ… å®Ÿè£…æ¸ˆã¿ |
| `AUTO_INDEX_ENABLED` | `true` | è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã®æœ‰åŠ¹/ç„¡åŠ¹ | âœ… å®Ÿè£…æ¸ˆã¿ |
| `AUTO_INDEX_STRATEGY` | `immediate` | è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ | âœ… å®Ÿè£…æ¸ˆã¿ |
| `BATCH_SIZE` | `10` | ãƒãƒƒãƒå‡¦ç†æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•° | ğŸš§ å†…éƒ¨å®Ÿè£…æ¸ˆã¿ã€è¨­å®šå…¬é–‹å¾…ã¡ |
| `BATCH_TIMEOUT` | `30.0` | ãƒãƒƒãƒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰ | ğŸš§ å†…éƒ¨å®Ÿè£…æ¸ˆã¿ã€è¨­å®šå…¬é–‹å¾…ã¡ |

#### è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥ã®è©³ç´°

- **`immediate`**: ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ/æ›´æ–°æ™‚ã«å³åº§ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
  - **åˆ©ç‚¹**: å¸¸ã«æœ€æ–°ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çŠ¶æ…‹ã‚’ç¶­æŒ
  - **æ¬ ç‚¹**: ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã®ãŸã³ã«å‡¦ç†è² è·
  - **é©ç”¨å ´é¢**: å°è¦æ¨¡vaultã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§é‡è¦–

- **`batch`**: ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚’ãƒãƒƒãƒåŒ–ã—ã¦å®šæœŸå‡¦ç†
  - **åˆ©ç‚¹**: å‡¦ç†åŠ¹ç‡ãŒè‰¯ã„ã€ã‚·ã‚¹ãƒ†ãƒ è² è·ã‚’åˆ†æ•£
  - **æ¬ ç‚¹**: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã«é…å»¶
  - **é©ç”¨å ´é¢**: ä¸­è¦æ¨¡vaultã€åŠ¹ç‡é‡è¦–

- **`background`**: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã®ç¶™ç¶šçš„å‡¦ç†
  - **åˆ©ç‚¹**: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„
  - **æ¬ ç‚¹**: è¤‡é›‘ãªå®Ÿè£…ã€ãƒ‡ãƒãƒƒã‚°ãŒå›°é›£
  - **é©ç”¨å ´é¢**: å¤§è¦æ¨¡vaultã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–

#### åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ãƒ¢ãƒ‡ãƒ«å | æ¬¡å…ƒæ•° | è¨€èªã‚µãƒãƒ¼ãƒˆ | ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ | æ¨å¥¨ç”¨é€” |
|----------|--------|-------------|---------------|----------|
| `all-MiniLM-L6-v2` | 384 | å¤šè¨€èª | é«˜é€Ÿ | ä¸€èˆ¬ç”¨é€”ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ |
| `all-mpnet-base-v2` | 768 | è‹±èªãƒ¡ã‚¤ãƒ³ | ä¸­é€Ÿ | é«˜ç²¾åº¦è‹±èªæ¤œç´¢ |
| `paraphrase-multilingual-MiniLM-L12-v2` | 384 | å¤šè¨€èªå¼·åŒ– | ä¸­é€Ÿ | æ—¥æœ¬èªã‚³ãƒ³ãƒ†ãƒ³ãƒ„é‡è¦– |

**æ³¨æ„**: åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´ã™ã‚‹å ´åˆã¯ã€æ—¢å­˜ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

```python
# 1. è¨­å®šç¢ºèª
get_vector_index_status()

# 2. å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ
build_vector_index_batch(max_files=5, force_rebuild=True)

# 3. å‹•ä½œç¢ºèª
semantic_search("ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒª", limit=3)

# 4. å…¨ä½“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
build_vector_index()
```

## æ¤œç´¢æ©Ÿèƒ½

### semantic_search

**æ¦‚è¦**: è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚’å®Ÿè¡Œ

```python
semantic_search(
    query: str,
    limit: int = 10,
    threshold: float | None = None,
    directory: str | None = None
) -> list[SemanticSearchResult]
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `query`: æ¤œç´¢ã—ãŸã„å†…å®¹ã®è‡ªç„¶è¨€èªè¨˜è¿°
- `limit`: è¿”ã™çµæœã®æœ€å¤§æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰
- `threshold`: æœ€å°é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ 0.0-1.0ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- `directory`: æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: vaultå…¨ä½“ï¼‰

**è¿”ã‚Šå€¤**: `SemanticSearchResult`ã®ãƒªã‚¹ãƒˆ
- `file_path`: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
- `similarity_score`: é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰
- `content_preview`: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
- `metadata`: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿

**ä½¿ç”¨ä¾‹**:
```python
# åŸºæœ¬çš„ãªæ¤œç´¢
results = semantic_search("æ©Ÿæ¢°å­¦ç¿’ã®æ¦‚å¿µ")

# é–¾å€¤ã‚’è¨­å®šã—ãŸé«˜ç²¾åº¦æ¤œç´¢
results = semantic_search("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»", limit=5, threshold=0.7)

# ç‰¹å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã§ã®æ¤œç´¢
results = semantic_search("ãƒ‡ãƒ¼ã‚¿åˆ†æ", directory="research")
```

**ã‚¨ãƒ©ãƒ¼æ¡ä»¶**:
- `RuntimeError`: ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹
- `ImportError`: å¿…è¦ãªä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„
- `ValueError`: ç„¡åŠ¹ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤

### find_similar_notes

**æ¦‚è¦**: æŒ‡å®šã•ã‚ŒãŸãƒãƒ¼ãƒˆã«é¡ä¼¼ã™ã‚‹ãƒãƒ¼ãƒˆã‚’æ¤œç´¢

```python
find_similar_notes(
    filename: str | None = None,
    filepath: str | None = None,
    default_path: str | None = None,
    limit: int = 5,
    exclude_self: bool = True
) -> list[SemanticSearchResult]
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `filename`: å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ`filepath`ã¨æ’ä»–çš„ï¼‰
- `filepath`: å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãƒ‘ã‚¹ï¼ˆ`filename`ã¨æ’ä»–çš„ï¼‰
- `default_path`: ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢æ™‚ã®ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- `limit`: è¿”ã™çµæœã®æœ€å¤§æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
- `exclude_self`: å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«è‡ªä½“ã‚’çµæœã‹ã‚‰é™¤å¤–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: trueï¼‰

**ä½¿ç”¨ä¾‹**:
```python
# ãƒ•ã‚¡ã‚¤ãƒ«åã§æŒ‡å®š
similar = find_similar_notes(filename="project-analysis.md")

# å®Œå…¨ãƒ‘ã‚¹ã§æŒ‡å®š
similar = find_similar_notes(filepath="/vault/research/paper.md", limit=3)

# ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§
similar = find_similar_notes(
    filename="meeting.md",
    default_path="work",
    exclude_self=False
)
```

**ã‚¨ãƒ©ãƒ¼æ¡ä»¶**:
- `FileNotFoundError`: æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
- `RuntimeError`: ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„
- `ValueError`: `filename`ã¨`filepath`ã®ä¸¡æ–¹ã¾ãŸã¯ä¸¡æ–¹ã¨ã‚‚æœªæŒ‡å®š

### find_duplicate_notes

**æ¦‚è¦**: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯é¡ä¼¼åº¦ã‚’ä½¿ç”¨ã—ã¦é‡è¤‡ã®å¯èƒ½æ€§ãŒã‚ã‚‹ãƒãƒ¼ãƒˆã‚’æ¤œå‡º

```python
find_duplicate_notes(
    similarity_threshold: float = 0.85,
    directory: str | None = None,
    min_content_length: int = 100,
    exclude_frontmatter: bool = True
) -> dict
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `similarity_threshold`: é‡è¤‡åˆ¤å®šã®é¡ä¼¼åº¦é–¾å€¤ 0.0-1.0ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.85ï¼‰
- `directory`: æ¤œç´¢å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆNoneã®å ´åˆvaultå…¨ä½“ï¼‰
- `min_content_length`: æ¤œè¨å¯¾è±¡ã®æœ€å°ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•·ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 100ãƒã‚¤ãƒˆï¼‰
- `exclude_frontmatter`: åˆ†ææ™‚ã«ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’é™¤å¤–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰

**è¿”ã‚Šå€¤**:
```python
{
    "duplicate_groups": [
        {
            "group_id": int,                    # ã‚°ãƒ«ãƒ¼ãƒ—ID
            "files": [
                {
                    "file_path": str,           # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
                    "similarity_score": float,  # é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢
                    "content_length": int,      # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é•·
                    "preview": str              # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                }
            ],
            "average_similarity": float,        # ã‚°ãƒ«ãƒ¼ãƒ—å†…å¹³å‡é¡ä¼¼åº¦
            "max_similarity": float,           # ã‚°ãƒ«ãƒ¼ãƒ—å†…æœ€å¤§é¡ä¼¼åº¦
            "recommendation": str              # çµ±åˆæ¨å¥¨äº‹é …
        }
    ],
    "statistics": {
        "total_files_analyzed": int,        # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°
        "duplicate_groups_found": int,      # æ¤œå‡ºã•ã‚ŒãŸé‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—æ•°
        "total_duplicates": int,            # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°
        "potential_space_savings": int,     # çµ±åˆã«ã‚ˆã‚‹æ¨å®šå‰Šæ¸›ã‚µã‚¤ã‚º
        "analysis_time_seconds": float     # åˆ†ææ™‚é–“ï¼ˆç§’ï¼‰
    },
    "analysis_time": str                    # åˆ†ææ™‚é–“ï¼ˆäººé–“ãŒèª­ã‚ã‚‹å½¢å¼ï¼‰
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ã®é‡è¤‡æ¤œå‡º
result = find_duplicate_notes()

# é«˜ç²¾åº¦ã§ã®é‡è¤‡æ¤œå‡ºï¼ˆå³ã—ã„é–¾å€¤ï¼‰
result = find_duplicate_notes(similarity_threshold=0.9)

# ç‰¹å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã®é‡è¤‡æ¤œå‡º
result = find_duplicate_notes(
    similarity_threshold=0.8,
    directory="meeting-notes"
)

# çŸ­ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚‚å«ã‚ãŸé‡è¤‡æ¤œå‡º
result = find_duplicate_notes(
    similarity_threshold=0.75,
    min_content_length=50
)

# çµæœã®æ´»ç”¨
for group in result["duplicate_groups"]:
    print(f"é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ— {group['group_id']} (é¡ä¼¼åº¦: {group['max_similarity']:.2f})")
    for file_info in group["files"]:
        print(f"  - {file_info['file_path']} ({file_info['content_length']} bytes)")
    print(f"  æ¨å¥¨: {group['recommendation']}")
```

**æ´»ç”¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼**:
```python
# 1. é‡è¤‡æ¤œå‡ºã®å®Ÿè¡Œ
duplicates = find_duplicate_notes(similarity_threshold=0.85)

# 2. çµ±è¨ˆæƒ…å ±ã®ç¢ºèª
stats = duplicates["statistics"]
print(f"åˆ†æãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files_analyzed']}")
print(f"é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—: {stats['duplicate_groups_found']}")
print(f"å‰Šæ¸›å¯èƒ½ã‚µã‚¤ã‚º: {stats['potential_space_savings']} bytes")

# 3. å„ã‚°ãƒ«ãƒ¼ãƒ—ã®è©³ç´°ç¢ºèª
for group in duplicates["duplicate_groups"]:
    print(f"\n=== ã‚°ãƒ«ãƒ¼ãƒ— {group['group_id']} ===")
    print(f"å¹³å‡é¡ä¼¼åº¦: {group['average_similarity']:.2f}")

    # ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ã®è¡¨ç¤º
    for file_info in group["files"]:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {file_info['file_path']}")
        print(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {file_info['preview'][:100]}...")
```

**é¡ä¼¼åº¦é–¾å€¤ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³**:
- **0.95-1.0**: ã»ã¼åŒä¸€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆèª¤å­—ä¿®æ­£ç¨‹åº¦ã®å·®ç•°ï¼‰
- **0.85-0.95**: é«˜ã„é¡ä¼¼æ€§ï¼ˆæ§‹é€ ã‚„ãƒˆãƒ”ãƒƒã‚¯ãŒåŒã˜ï¼‰
- **0.70-0.85**: ä¸­ç¨‹åº¦ã®é¡ä¼¼æ€§ï¼ˆé–¢é€£ã™ã‚‹ãŒç•°ãªã‚‹å†…å®¹ï¼‰
- **0.50-0.70**: ä½ã„é¡ä¼¼æ€§ï¼ˆéƒ¨åˆ†çš„ãªé‡è¤‡ï¼‰

**ã‚¨ãƒ©ãƒ¼æ¡ä»¶**:
- `RuntimeError`: ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ãŒç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã‚‹
- `ImportError`: å¿…è¦ãªä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„
- `ValueError`: ç„¡åŠ¹ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€¤ï¼ˆé–¾å€¤ç¯„å›²å¤–ç­‰ï¼‰

**æ³¨æ„äº‹é …**:
- å¤§è¦æ¨¡ãªvaultã§ã¯å‡¦ç†æ™‚é–“ãŒé•·ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
- `exclude_frontmatter=True`ã§ã¯ä½œæˆæ—¥ç­‰ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¯æ¯”è¼ƒã«å«ã¾ã‚Œã¾ã›ã‚“
- éå¸¸ã«çŸ­ã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`min_content_length`æœªæº€ï¼‰ã¯åˆ†æå¯¾è±¡å¤–ã§ã™
- é‡è¤‡åˆ¤å®šã¯å†…å®¹ã®æ„å‘³çš„é¡ä¼¼æ€§ã«åŸºã¥ãã€ãƒ•ã‚¡ã‚¤ãƒ«åã¯è€ƒæ…®ã•ã‚Œã¾ã›ã‚“

## ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†

### build_vector_index

**æ¦‚è¦**: Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨ãªãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ

```python
build_vector_index(
    directory: str | None = None,
    file_pattern: str = "*.md",
    force_rebuild: bool = False
) -> dict[str, int | list[str]]
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `directory`: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: vaultå…¨ä½“ï¼‰
- `file_pattern`: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "*.md"ï¼‰
- `force_rebuild`: æ—¢å­˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å¼·åˆ¶å†æ§‹ç¯‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰

**è¿”ã‚Šå€¤**:
```python
{
    "processed": int,    # å‡¦ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
    "skipped": int,      # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
    "errors": list[str]  # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
}
```

**ä½¿ç”¨ä¾‹**:
```python
# å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
result = build_vector_index()

# ç‰¹å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å¼·åˆ¶å†æ§‹ç¯‰
result = build_vector_index(directory="research", force_rebuild=True)

# ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
result = build_vector_index(file_pattern="*.txt")
```

### build_vector_index_batch

**æ¦‚è¦**: å°è¦æ¨¡ãƒãƒƒãƒã§ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆMCP Inspectorå®‰å…¨ï¼‰

```python
build_vector_index_batch(
    directory: str | None = None,
    file_pattern: str = "*.md",
    max_files: int = 5,
    force_rebuild: bool = False
) -> dict[str, int | list[str]]
```

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `directory`: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: vaultå…¨ä½“ï¼‰
- `file_pattern`: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "*.md"ï¼‰
- `max_files`: 1å›ã®å‡¦ç†ã§æ‰±ã†æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ã€ä¸Šé™: 100ï¼‰
- `force_rebuild`: æ—¢å­˜ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å¼·åˆ¶å†æ§‹ç¯‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: falseï¼‰

**è¿”ã‚Šå€¤**:
```python
{
    "processed": int,         # å‡¦ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
    "skipped": int,           # ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
    "errors": list[str],      # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    "total_files_found": int  # ç™ºè¦‹ã•ã‚ŒãŸç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°
}
```

**ä½¿ç”¨ä¾‹**:
```python
# MCP Inspectorã§ã®å®‰å…¨ãªãƒ†ã‚¹ãƒˆ
result = build_vector_index_batch(max_files=1, force_rebuild=True)

# ä¸­è¦æ¨¡ãƒãƒƒãƒå‡¦ç†
result = build_vector_index_batch(max_files=20)

# ç‰¹å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ®µéšçš„å‡¦ç†
result = build_vector_index_batch(directory="drafts", max_files=10)
```

**ã‚»ãƒ¼ãƒ•ãƒ†ã‚£æ©Ÿèƒ½**:
- `max_files`ã®ä¸Šé™åˆ¶é™ï¼ˆ100ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œè¨¼
- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®æ¤œè¨¼ï¼ˆvaultå¤–ã‚¢ã‚¯ã‚»ã‚¹é˜²æ­¢ï¼‰

### get_vector_index_status

**æ¦‚è¦**: ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—

```python
get_vector_index_status() -> dict[str, int | bool | str]
```

**è¿”ã‚Šå€¤**:
```python
{
    "vector_search_enabled": bool,     # ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã®æœ‰åŠ¹/ç„¡åŠ¹
    "database_exists": bool,           # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨
    "indexed_files": int,              # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°
    "total_files": int,                # ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°
    "index_completeness": float,       # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œæˆåº¦ï¼ˆ0.0-1.0ï¼‰
    "database_size": int,              # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µã‚¤ã‚ºï¼ˆãƒã‚¤ãƒˆï¼‰
    "last_updated": str,               # æœ€çµ‚æ›´æ–°æ—¥æ™‚
    "embedding_model": str             # ä½¿ç”¨ä¸­ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ç¾åœ¨ã®çŠ¶æ…‹ç¢ºèª
status = get_vector_index_status()
print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®Œæˆåº¦: {status['index_completeness']:.1%}")
print(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¸ˆã¿: {status['indexed_files']}/{status['total_files']} ãƒ•ã‚¡ã‚¤ãƒ«")
```

## ãƒãƒƒãƒå‡¦ç†

### process_batch_index

**æ¦‚è¦**: ä¿ç•™ä¸­ã®ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†

```python
process_batch_index() -> dict[str, Any]
```

**è¿”ã‚Šå€¤**:
```python
{
    "tasks_processed": int,      # å‡¦ç†ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯æ•°
    "queue_size_before": int,    # å‡¦ç†å‰ã®ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º
    "queue_size_after": int,     # å‡¦ç†å¾Œã®ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º
    "message": str               # å‡¦ç†çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ä¿ç•™ä¸­ã®ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†
result = process_batch_index()
print(f"å‡¦ç†æ¸ˆã¿ã‚¿ã‚¹ã‚¯: {result['tasks_processed']}")
```

**æ³¨æ„**: `immediate`æˆ¦ç•¥ã§ã¯æ©Ÿèƒ½ã—ã¾ã›ã‚“ã€‚`batch`ã¾ãŸã¯`background`æˆ¦ç•¥ã§ã®ã¿æœ‰åŠ¹ã€‚

### get_batch_index_status

**æ¦‚è¦**: ãƒãƒƒãƒã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’å–å¾—

```python
get_batch_index_status() -> dict[str, Any]
```

**è¿”ã‚Šå€¤**:
```python
{
    "auto_index_enabled": bool,      # è‡ªå‹•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ‰åŠ¹/ç„¡åŠ¹
    "auto_index_strategy": str,      # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æˆ¦ç•¥
    "vector_search_enabled": bool,   # ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã®æœ‰åŠ¹/ç„¡åŠ¹
    "queue_size": int,               # ç¾åœ¨ã®ã‚­ãƒ¥ãƒ¼ã‚µã‚¤ã‚º
    "tasks_queued": int,             # ã‚­ãƒ¥ãƒ¼ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯æ•°
    "tasks_processed": int,          # å‡¦ç†æ¸ˆã¿ã‚¿ã‚¹ã‚¯æ•°
    "batches_processed": int,        # å‡¦ç†æ¸ˆã¿ãƒãƒƒãƒæ•°
    "errors": int                    # ã‚¨ãƒ©ãƒ¼æ•°
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ãƒãƒƒãƒã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ç¢ºèª
status = get_batch_index_status()
if status["queue_size"] > 0:
    print(f"å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯: {status['queue_size']}")
    process_batch_index()
```

## ãƒ‡ãƒãƒƒã‚°ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### debug_vector_schema

**æ¦‚è¦**: ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è©³ç´°è¨ºæ–­æƒ…å ±ã‚’å–å¾—

```python
debug_vector_schema() -> dict
```

**è¿”ã‚Šå€¤**:
```python
{
    "embedding_model": str,              # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
    "test_embedding_dimension": int,     # ãƒ†ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒæ•°
    "test_embedding_type": str,          # åŸ‹ã‚è¾¼ã¿ã®ãƒ‡ãƒ¼ã‚¿å‹
    "database_path": str,                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    "database_exists": bool,             # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨
    "existing_tables": list[str],        # æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒªã‚¹ãƒˆ
    "vectors_table_schema": dict,        # ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒ
    "database_error": str                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
}
```

**ä½¿ç”¨ä¾‹**:
```python
# è©³ç´°è¨ºæ–­ã®å®Ÿè¡Œ
debug_info = debug_vector_schema()
print(f"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {debug_info['test_embedding_dimension']}")
print(f"æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«: {debug_info['existing_tables']}")

# æ¬¡å…ƒãƒŸã‚¹ãƒãƒƒãƒã®è¨ºæ–­
if debug_info['test_embedding_dimension'] != 384:
    print("è­¦å‘Š: äºˆæœŸã—ãªã„åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ")
```

**è¨ºæ–­é …ç›®**:
- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®å‹•ä½œç¢ºèª
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
- ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®æ¤œè¨¼
- æ¬¡å…ƒæ•´åˆæ€§ã®ãƒã‚§ãƒƒã‚¯

### reset_vector_database

**æ¦‚è¦**: ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ

```python
reset_vector_database() -> dict[str, str]
```

**è¿”ã‚Šå€¤**:
```python
{
    "status": str  # æ“ä½œã®çµæœãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
}
```

**ä½¿ç”¨ä¾‹**:
```python
# æ¬¡å…ƒãƒŸã‚¹ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼ã®ä¿®å¾©
reset_result = reset_vector_database()
print(reset_result["status"])

# ãƒªã‚»ãƒƒãƒˆå¾Œã®å†æ§‹ç¯‰
build_vector_index()
```

**æ³¨æ„**: ã“ã®æ“ä½œã¯ä¸å¯é€†çš„ã§ã™ã€‚æ—¢å­˜ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã™ã€‚

**ä½¿ç”¨å ´é¢**:
- æ¬¡å…ƒãƒŸã‚¹ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼ã®è§£æ±º
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç ´æã®ä¿®å¾©
- åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å¤‰æ›´æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
- é–‹ç™º/ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆ

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ä¸€èˆ¬çš„ãªã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•

#### ImportError: ä¾å­˜é–¢ä¿‚ä¸è¶³
```python
# ã‚¨ãƒ©ãƒ¼: sentence-transformers is required
# è§£æ±º: ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install "minerva[vector]"
```

#### RuntimeError: ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ç„¡åŠ¹
```python
# ã‚¨ãƒ©ãƒ¼: Vector search is not enabled
# è§£æ±º: ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
VECTOR_SEARCH_ENABLED=true
```

#### æ¬¡å…ƒãƒŸã‚¹ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼
```python
# ã‚¨ãƒ©ãƒ¼: Array arguments must be of the same size
# è§£æ±º: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒªã‚»ãƒƒãƒˆ
reset_vector_database()
build_vector_index()
```

#### FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨
```python
# ã‚¨ãƒ©ãƒ¼: Specified file does not exist
# è§£æ±º: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®ç¢ºèª
get_vector_index_status()  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
```

### ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

1. **æ®µéšçš„è¨ºæ–­**: `get_vector_index_status` â†’ `debug_vector_schema`
2. **å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ**: `build_vector_index_batch`ã§ãƒ†ã‚¹ãƒˆå¾Œã€å…¨ä½“å‡¦ç†
3. **ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: é‡è¦ãªãƒ‡ãƒ¼ã‚¿ã¯äº‹å‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
4. **ãƒ­ã‚°ç¢ºèª**: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è©³ç´°ãªè¨˜éŒ²

## ä½¿ç”¨ä¾‹ã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### åˆå›ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒç¢ºèª
status = get_vector_index_status()
if not status["vector_search_enabled"]:
    print("ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã‚’æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„")
    exit()

# ã‚¹ãƒ†ãƒƒãƒ—2: å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ
print("å°è¦æ¨¡ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
test_result = build_vector_index_batch(max_files=5, force_rebuild=True)
print(f"ãƒ†ã‚¹ãƒˆçµæœ: {test_result['processed']} ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†")

# ã‚¹ãƒ†ãƒƒãƒ—3: å‹•ä½œç¢ºèª
print("å‹•ä½œç¢ºèªã‚’å®Ÿè¡Œä¸­...")
search_results = semantic_search("ãƒ†ã‚¹ãƒˆ", limit=3)
print(f"æ¤œç´¢çµæœ: {len(search_results)} ä»¶")

# ã‚¹ãƒ†ãƒƒãƒ—4: å…¨ä½“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
print("å…¨ä½“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã‚’å®Ÿè¡Œä¸­...")
full_result = build_vector_index()
print(f"å®Œäº†: {full_result['processed']} ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†")
```

### å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: ç¾çŠ¶ç¢ºèª
status = get_vector_index_status()
print(f"å®Œæˆåº¦: {status['index_completeness']:.1%}")

# ã‚¹ãƒ†ãƒƒãƒ—2: æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½åŠ 
if status["index_completeness"] < 1.0:
    print("æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ä¸­...")
    result = build_vector_index(force_rebuild=False)
    print(f"è¿½åŠ : {result['processed']} ãƒ•ã‚¡ã‚¤ãƒ«")

# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒƒãƒå‡¦ç†ç¢ºèª
batch_status = get_batch_index_status()
if batch_status["queue_size"] > 0:
    print("ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
    process_batch_index()
```

### é¡ä¼¼ãƒãƒ¼ãƒˆç™ºè¦‹ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: å‚ç…§ãƒãƒ¼ãƒˆã®é¡ä¼¼ãƒãƒ¼ãƒˆæ¤œç´¢
reference_file = "important-project.md"
similar_notes = find_similar_notes(filename=reference_file, limit=10)

print(f"{reference_file} ã«é¡ä¼¼ã™ã‚‹ãƒãƒ¼ãƒˆ:")
for note in similar_notes:
    print(f"- {note.file_path} (é¡ä¼¼åº¦: {note.similarity_score:.2f})")

# ã‚¹ãƒ†ãƒƒãƒ—2: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã§é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç™ºè¦‹
related_content = semantic_search("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨ˆç”»", threshold=0.6)
print(f"\né–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ({len(related_content)} ä»¶):")
for content in related_content:
    print(f"- {content.file_path}: {content.content_preview[:100]}...")
```

### é‡è¤‡ãƒãƒ¼ãƒˆæ¤œå‡ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: åŸºæœ¬çš„ãªé‡è¤‡æ¤œå‡º
print("=== é‡è¤‡ãƒãƒ¼ãƒˆæ¤œå‡º ===")
duplicates = find_duplicate_notes(similarity_threshold=0.85)

# ã‚¹ãƒ†ãƒƒãƒ—2: çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
stats = duplicates["statistics"]
print(f"åˆ†æå¯¾è±¡: {stats['total_files_analyzed']} ãƒ•ã‚¡ã‚¤ãƒ«")
print(f"é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—: {stats['duplicate_groups_found']} å€‹")
print(f"é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«: {stats['total_duplicates']} ä»¶")
print(f"å‰Šæ¸›å¯èƒ½ã‚µã‚¤ã‚º: {stats['potential_space_savings']:,} bytes")
print(f"åˆ†ææ™‚é–“: {duplicates['analysis_time']}")

# ã‚¹ãƒ†ãƒƒãƒ—3: é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ã®è©³ç´°ç¢ºèª
if duplicates["duplicate_groups"]:
    print("\n=== é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—è©³ç´° ===")
    for i, group in enumerate(duplicates["duplicate_groups"], 1):
        print(f"\nã‚°ãƒ«ãƒ¼ãƒ— {i} (ID: {group['group_id']})")
        print(f"å¹³å‡é¡ä¼¼åº¦: {group['average_similarity']:.2f}")
        print(f"æœ€å¤§é¡ä¼¼åº¦: {group['max_similarity']:.2f}")
        print(f"æ¨å¥¨äº‹é …: {group['recommendation']}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
        print("å«ã¾ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:")
        for file_info in group["files"]:
            print(f"  - {file_info['file_path']}")
            print(f"    é¡ä¼¼åº¦: {file_info['similarity_score']:.2f}")
            print(f"    ã‚µã‚¤ã‚º: {file_info['content_length']:,} bytes")
            print(f"    ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {file_info['preview'][:80]}...")
else:
    print("\né‡è¤‡ãƒãƒ¼ãƒˆã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

# ã‚¹ãƒ†ãƒƒãƒ—4: ç‰¹å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã®è©³ç´°æ¤œç´¢ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
print("\n=== ä¼šè­°ãƒãƒ¼ãƒˆã®é‡è¤‡æ¤œå‡º ===")
meeting_duplicates = find_duplicate_notes(
    similarity_threshold=0.8,
    directory="meetings",
    min_content_length=200
)
if meeting_duplicates["duplicate_groups"]:
    print(f"ä¼šè­°ãƒãƒ¼ãƒˆã§ {len(meeting_duplicates['duplicate_groups'])} å€‹ã®é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ¤œå‡º")
```

### ãƒˆãƒ©ãƒ–ãƒ«è¨ºæ–­ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```python
# ã‚¹ãƒ†ãƒƒãƒ—1: åŸºæœ¬è¨ºæ–­
print("=== åŸºæœ¬è¨ºæ–­ ===")
status = get_vector_index_status()
print(f"ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢: {'æœ‰åŠ¹' if status['vector_search_enabled'] else 'ç„¡åŠ¹'}")
print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {'å­˜åœ¨' if status['database_exists'] else 'ä¸å­˜åœ¨'}")

# ã‚¹ãƒ†ãƒƒãƒ—2: è©³ç´°è¨ºæ–­
print("\n=== è©³ç´°è¨ºæ–­ ===")
debug_info = debug_vector_schema()
print(f"åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ: {debug_info.get('test_embedding_dimension', 'N/A')}")
print(f"æ—¢å­˜ãƒ†ãƒ¼ãƒ–ãƒ«: {debug_info.get('existing_tables', [])}")

# ã‚¹ãƒ†ãƒƒãƒ—3: å•é¡ŒãŒã‚ã‚Œã°ä¿®å¾©
if debug_info.get('database_error') or debug_info.get('test_embedding_dimension') != 384:
    print("\n=== ä¿®å¾©å®Ÿè¡Œ ===")
    reset_result = reset_vector_database()
    print(reset_result["status"])

    # å†æ§‹ç¯‰
    build_result = build_vector_index()
    print(f"å†æ§‹ç¯‰å®Œäº†: {build_result['processed']} ãƒ•ã‚¡ã‚¤ãƒ«")
```

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [vector_search_troubleshooting.md](vector_search_troubleshooting.md) - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°è©³ç´°ã‚¬ã‚¤ãƒ‰
- [technical_spec.md](technical_spec.md) - æŠ€è¡“ä»•æ§˜ã¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
- [optional_dependencies.md](optional_dependencies.md) - ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾å­˜é–¢ä¿‚ã®å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³
- [CLAUDE.md](../CLAUDE.md) - é–‹ç™ºè€…å‘ã‘è©³ç´°æƒ…å ±

## ã‚µãƒãƒ¼ãƒˆ

å•é¡ŒãŒç™ºç”Ÿã—ãŸå ´åˆ:

1. [GitHub Issues](https://github.com/kk6/minerva/issues) ã§å ±å‘Š
2. `debug_vector_schema()`ã®å‡ºåŠ›çµæœã‚’æ·»ä»˜
3. ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å…¨æ–‡ã‚’è¨˜è¼‰
4. ä½¿ç”¨ç’°å¢ƒï¼ˆOSã€Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã€vault ã‚µã‚¤ã‚ºï¼‰ã‚’æ˜è¨˜
